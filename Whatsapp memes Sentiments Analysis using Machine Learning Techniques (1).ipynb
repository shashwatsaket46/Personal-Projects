{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02598,
     "end_time": "2020-12-06T05:31:10.490068",
     "exception": false,
     "start_time": "2020-12-06T05:31:10.464088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:10.544240Z",
     "iopub.status.busy": "2020-12-06T05:31:10.543523Z",
     "iopub.status.idle": "2020-12-06T05:31:16.654637Z",
     "shell.execute_reply": "2020-12-06T05:31:16.653976Z"
    },
    "papermill": {
     "duration": 6.142071,
     "end_time": "2020-12-06T05:31:16.654744",
     "exception": false,
     "start_time": "2020-12-06T05:31:10.512673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015116,
     "end_time": "2020-12-06T05:31:16.686095",
     "exception": false,
     "start_time": "2020-12-06T05:31:16.670979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reading Image Info from CSV and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:16.721020Z",
     "iopub.status.busy": "2020-12-06T05:31:16.720091Z",
     "iopub.status.idle": "2020-12-06T05:31:16.842056Z",
     "shell.execute_reply": "2020-12-06T05:31:16.842839Z"
    },
    "papermill": {
     "duration": 0.141297,
     "end_time": "2020-12-06T05:31:16.843012",
     "exception": false,
     "start_time": "2020-12-06T05:31:16.701715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name                                     text_corrected  \\\n",
       "0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
       "2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
       "4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "       humour          sarcasm       offensive      motivational  \\\n",
       "0   hilarious          general   not_offensive  not_motivational   \n",
       "1   not_funny          general   not_offensive      motivational   \n",
       "2  very_funny    not_sarcastic   not_offensive  not_motivational   \n",
       "3  very_funny  twisted_meaning  very_offensive      motivational   \n",
       "4   hilarious     very_twisted  very_offensive  not_motivational   \n",
       "\n",
       "  overall_sentiment  \n",
       "0     very_positive  \n",
       "1     very_positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4           neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\dataset\\\\labels.csv')\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df = df.drop(columns = ['text_ocr'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:16.883866Z",
     "iopub.status.busy": "2020-12-06T05:31:16.882788Z",
     "iopub.status.idle": "2020-12-06T05:31:16.908018Z",
     "shell.execute_reply": "2020-12-06T05:31:16.908470Z"
    },
    "papermill": {
     "duration": 0.044993,
     "end_time": "2020-12-06T05:31:16.908617",
     "exception": false,
     "start_time": "2020-12-06T05:31:16.863624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>image_120.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>image_4800.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>image_6782.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>image_6785.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>image_6787.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_name text_corrected      humour          sarcasm  \\\n",
       "119    image_120.jpg            NaN   not_funny          general   \n",
       "4799  image_4800.jpg            NaN  very_funny          general   \n",
       "6781  image_6782.jpg            NaN  very_funny  twisted_meaning   \n",
       "6784  image_6785.jpg            NaN   hilarious          general   \n",
       "6786  image_6787.jpg            NaN   not_funny    not_sarcastic   \n",
       "\n",
       "           offensive      motivational overall_sentiment  \n",
       "119    not_offensive  not_motivational          positive  \n",
       "4799          slight      motivational           neutral  \n",
       "6781   not_offensive  not_motivational          positive  \n",
       "6784   not_offensive  not_motivational          positive  \n",
       "6786  very_offensive      motivational          positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:16.955734Z",
     "iopub.status.busy": "2020-12-06T05:31:16.954832Z",
     "iopub.status.idle": "2020-12-06T05:31:16.987302Z",
     "shell.execute_reply": "2020-12-06T05:31:16.987799Z"
    },
    "papermill": {
     "duration": 0.062218,
     "end_time": "2020-12-06T05:31:16.987966",
     "exception": false,
     "start_time": "2020-12-06T05:31:16.925748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name           False\n",
       "text_corrected       False\n",
       "humour               False\n",
       "sarcasm              False\n",
       "offensive            False\n",
       "motivational         False\n",
       "overall_sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = df.copy()\n",
    "cleaned.dropna(inplace=True)\n",
    "cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:17.026502Z",
     "iopub.status.busy": "2020-12-06T05:31:17.025873Z",
     "iopub.status.idle": "2020-12-06T05:31:17.042722Z",
     "shell.execute_reply": "2020-12-06T05:31:17.041451Z"
    },
    "papermill": {
     "duration": 0.037342,
     "end_time": "2020-12-06T05:31:17.042857",
     "exception": false,
     "start_time": "2020-12-06T05:31:17.005515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image(dataframe):\n",
    "    \n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "    width = 100\n",
    "    height = 100\n",
    "    X = []\n",
    "    path = 'D:\\\\dataset\\\\images\\\\'+dataframe['image_name']\n",
    "    \n",
    "    for i in tqdm(range(dataframe.shape[0])):\n",
    "        if i in [119, 4799, 6781, 6784, 6786]:\n",
    "            pass\n",
    "        else:\n",
    "            img = image.load_img(path[i],target_size=(width,height,3))\n",
    "            img = ImageOps.grayscale(img)\n",
    "            img = image.img_to_array(img)\n",
    "            img = img/255.0\n",
    "            X.append(img)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], 100*100)\n",
    "    \n",
    "    rows_to_drop = ['image_120.jpg', 'image_4800.jpg', 'image_6782.jpg', 'image_6785.jpg', 'image_6787.jpg',\n",
    "                    'image_6988.jpg', 'image_6989.jpg', 'image_6990.png', 'image_6991.jpg', 'image_6992.jpg']\n",
    "    \n",
    "    for images in rows_to_drop:\n",
    "        dataframe.drop(dataframe[dataframe['image_name'] == images].index, inplace=True)\n",
    "        \n",
    "    text_data = CountVectorizer().fit_transform(dataframe['text_corrected'].values)\n",
    "    text_data = TfidfTransformer().fit_transform(text_data).toarray()\n",
    "    \n",
    "    features = np.hstack((X, text_data))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:31:17.091391Z",
     "iopub.status.busy": "2020-12-06T05:31:17.090464Z",
     "iopub.status.idle": "2020-12-06T05:33:02.859270Z",
     "shell.execute_reply": "2020-12-06T05:33:02.860242Z"
    },
    "papermill": {
     "duration": 105.799524,
     "end_time": "2020-12-06T05:33:02.860435",
     "exception": false,
     "start_time": "2020-12-06T05:31:17.060911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████▍   | 6670/6987 [01:48<00:04, 68.59it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 6987/6987 [01:53<00:00, 61.38it/s]\n"
     ]
    }
   ],
   "source": [
    "X = get_image(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:33:03.952136Z",
     "iopub.status.busy": "2020-12-06T05:33:03.951232Z",
     "iopub.status.idle": "2020-12-06T05:33:03.956114Z",
     "shell.execute_reply": "2020-12-06T05:33:03.956778Z"
    },
    "papermill": {
     "duration": 0.333337,
     "end_time": "2020-12-06T05:33:03.956939",
     "exception": false,
     "start_time": "2020-12-06T05:33:03.623602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6982, 22915)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:33:04.588954Z",
     "iopub.status.busy": "2020-12-06T05:33:04.588341Z",
     "iopub.status.idle": "2020-12-06T05:33:04.596075Z",
     "shell.execute_reply": "2020-12-06T05:33:04.596539Z"
    },
    "papermill": {
     "duration": 0.332546,
     "end_time": "2020-12-06T05:33:04.596663",
     "exception": false,
     "start_time": "2020-12-06T05:33:04.264117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_target(dataframe):\n",
    "    target_A = dataframe.copy()['overall_sentiment']\n",
    "    target_A = pd.get_dummies(target_A)\n",
    "    \n",
    "    target_B = dataframe.copy()\n",
    "    target_B = target_B.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious':1},\n",
    "                        'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1},\n",
    "                        'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1},\n",
    "                        'motivational': {'not_motivational': 0, 'motivational': 1}})\n",
    "    target_B = target_B.iloc[:,2:6]\n",
    "    \n",
    "    df1 = pd.get_dummies(cleaned['sarcasm'])\n",
    "    df2 = pd.get_dummies(cleaned['humour'])\n",
    "    df3 = pd.get_dummies(cleaned['offensive'])\n",
    "    df4 = pd.get_dummies(cleaned['offensive'])\n",
    "    frames = [df1, df2, df3, df4]\n",
    "    target_C = pd.concat(frames, axis=1)\n",
    "    \n",
    "    return target_A, target_B, target_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:33:05.318998Z",
     "iopub.status.busy": "2020-12-06T05:33:05.317216Z",
     "iopub.status.idle": "2020-12-06T05:33:05.386951Z",
     "shell.execute_reply": "2020-12-06T05:33:05.388717Z"
    },
    "papermill": {
     "duration": 0.47549,
     "end_time": "2020-12-06T05:33:05.389019",
     "exception": false,
     "start_time": "2020-12-06T05:33:04.913529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_A, target_B, target_C = create_target(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:33:06.041165Z",
     "iopub.status.busy": "2020-12-06T05:33:06.040493Z",
     "iopub.status.idle": "2020-12-06T05:33:06.043508Z",
     "shell.execute_reply": "2020-12-06T05:33:06.044025Z"
    },
    "papermill": {
     "duration": 0.316046,
     "end_time": "2020-12-06T05:33:06.044155",
     "exception": false,
     "start_time": "2020-12-06T05:33:05.728109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.316016,
     "end_time": "2020-12-06T05:33:06.667539",
     "exception": false,
     "start_time": "2020-12-06T05:33:06.351523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:33:07.358794Z",
     "iopub.status.busy": "2020-12-06T05:33:07.353426Z",
     "iopub.status.idle": "2020-12-06T05:40:50.651889Z",
     "shell.execute_reply": "2020-12-06T05:40:50.652428Z"
    },
    "papermill": {
     "duration": 463.663695,
     "end_time": "2020-12-06T05:40:50.652563",
     "exception": false,
     "start_time": "2020-12-06T05:33:06.988868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23942208462332304\n",
      "0.08186085089395413\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(LogisticRegression(max_iter=10)).fit(X_train, y_train)\n",
    "\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.315379,
     "end_time": "2020-12-06T05:40:51.273728",
     "exception": false,
     "start_time": "2020-12-06T05:40:50.958349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:40:51.897895Z",
     "iopub.status.busy": "2020-12-06T05:40:51.897259Z",
     "iopub.status.idle": "2020-12-06T05:48:26.432361Z",
     "shell.execute_reply": "2020-12-06T05:48:26.432936Z"
    },
    "papermill": {
     "duration": 454.849518,
     "end_time": "2020-12-06T05:48:26.433105",
     "exception": false,
     "start_time": "2020-12-06T05:40:51.583587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7663950848136771\n",
      "0.6170548379951568\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(LogisticRegression(max_iter=1000)).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T05:48:27.053298Z",
     "iopub.status.busy": "2020-12-06T05:48:27.052419Z",
     "iopub.status.idle": "2020-12-06T06:15:16.219294Z",
     "shell.execute_reply": "2020-12-06T06:15:16.219854Z"
    },
    "papermill": {
     "duration": 1609.477544,
     "end_time": "2020-12-06T06:15:16.219987",
     "exception": false,
     "start_time": "2020-12-06T05:48:26.742443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3242838419771578\n",
      "0.23546016317896065\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(LogisticRegression(max_iter=100)).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.30473,
     "end_time": "2020-12-06T06:15:16.832072",
     "exception": false,
     "start_time": "2020-12-06T06:15:16.527342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T06:15:17.457630Z",
     "iopub.status.busy": "2020-12-06T06:15:17.451835Z",
     "iopub.status.idle": "2020-12-06T06:19:38.724303Z",
     "shell.execute_reply": "2020-12-06T06:19:38.725063Z"
    },
    "papermill": {
     "duration": 261.589555,
     "end_time": "2020-12-06T06:19:38.725253",
     "exception": false,
     "start_time": "2020-12-06T06:15:17.135698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19638826185101582\n",
      "0.07760364086034585\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T06:19:39.688468Z",
     "iopub.status.busy": "2020-12-06T06:19:39.687627Z",
     "iopub.status.idle": "2020-12-06T06:22:37.310460Z",
     "shell.execute_reply": "2020-12-06T06:22:37.311181Z"
    },
    "papermill": {
     "duration": 178.098827,
     "end_time": "2020-12-06T06:22:37.311340",
     "exception": false,
     "start_time": "2020-12-06T06:19:39.212513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7691699604743082\n",
      "0.6309681041917742\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T06:22:38.265770Z",
     "iopub.status.busy": "2020-12-06T06:22:38.260683Z",
     "iopub.status.idle": "2020-12-06T06:35:22.483430Z",
     "shell.execute_reply": "2020-12-06T06:35:22.484012Z"
    },
    "papermill": {
     "duration": 764.707153,
     "end_time": "2020-12-06T06:35:22.484151",
     "exception": false,
     "start_time": "2020-12-06T06:22:37.776998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1509433962264151\n",
      "0.0653611562843327\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.316166,
     "end_time": "2020-12-06T06:35:23.109275",
     "exception": false,
     "start_time": "2020-12-06T06:35:22.793109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T06:35:23.746034Z",
     "iopub.status.busy": "2020-12-06T06:35:23.745049Z",
     "iopub.status.idle": "2020-12-06T07:13:59.236766Z",
     "shell.execute_reply": "2020-12-06T07:13:59.237335Z"
    },
    "papermill": {
     "duration": 2315.817924,
     "end_time": "2020-12-06T07:13:59.237485",
     "exception": false,
     "start_time": "2020-12-06T06:35:23.419561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32248939179632247\n",
      "0.20017818890525238\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n",
    "\n",
    "clasifier_A = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_A.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T07:13:59.867339Z",
     "iopub.status.busy": "2020-12-06T07:13:59.866702Z",
     "iopub.status.idle": "2020-12-06T07:20:46.460313Z",
     "shell.execute_reply": "2020-12-06T07:20:46.460843Z"
    },
    "papermill": {
     "duration": 406.907824,
     "end_time": "2020-12-06T07:20:46.460979",
     "exception": false,
     "start_time": "2020-12-06T07:13:59.553155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6717034925160371\n",
      "0.6319939785565073\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n",
    "\n",
    "clasifier_B = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_B.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T07:20:47.118915Z",
     "iopub.status.busy": "2020-12-06T07:20:47.108559Z",
     "iopub.status.idle": "2020-12-06T09:00:20.457112Z",
     "shell.execute_reply": "2020-12-06T09:00:20.457631Z"
    },
    "papermill": {
     "duration": 5973.68747,
     "end_time": "2020-12-06T09:00:20.457783",
     "exception": false,
     "start_time": "2020-12-06T07:20:46.770313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33558959743498396\n",
      "0.24896645413184093\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n",
    "\n",
    "clasifier_C = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
    "prediction = clasifier_C.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, prediction, average='micro'))\n",
    "print(f1_score(y_test, prediction, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "duration": 12554.569202,
   "end_time": "2020-12-06T09:00:20.876632",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-06T05:31:06.307430",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
